I0117 19:40:23.308689 35429 caffe.cpp:217] Using GPUs 0
I0117 19:40:23.332375 35429 caffe.cpp:222] GPU 0: Tesla K40m
I0117 19:40:23.774821 35429 solver.cpp:48] Initializing solver from parameters: 
test_iter: 62
test_iter: 62
test_interval: 200
base_lr: 1e-05
display: 20
max_iter: 26000
lr_policy: "step"
gamma: 0.5
momentum: 0.9
stepsize: 1000
snapshot: 200
snapshot_prefix: "/workdir/hassony/new-video/video-caffe/examples/c3d_arrow/c3d_arrow_fb_no_drop/c3d_arrow_fb"
solver_mode: GPU
device_id: 0
net: "/workdir/hassony/new-video/video-caffe/examples/c3d_arrow/c3d_arrow_train_fb_no_drop.prototxt"
train_state {
  level: 0
  stage: ""
}
test_state {
  stage: "test-on-train"
}
test_state {
  stage: "test-on-val"
}
I0117 19:40:23.777326 35429 solver.cpp:91] Creating training net from net file: /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/c3d_arrow_train_fb_no_drop.prototxt
I0117 19:40:23.778569 35429 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0117 19:40:23.778602 35429 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0117 19:40:23.778642 35429 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer prob
I0117 19:40:23.778661 35429 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0117 19:40:23.778951 35429 net.cpp:58] Initializing net from parameters: 
name: "c3d_arrow"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "VideoData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 112
    mean_value: 90
    mean_value: 98
    mean_value: 102
  }
  video_data_param {
    source: "/workdir/hassony/new-video/video-caffe/examples/c3d_arrow/train-input-fb.txt"
    batch_size: 50
    shuffle: true
    new_length: 16
    new_height: 128
    new_width: 171
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "my-fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0117 19:40:23.781167 35429 layer_factory.hpp:77] Creating layer data
I0117 19:40:23.781251 35429 net.cpp:100] Creating Layer data
I0117 19:40:23.781283 35429 net.cpp:408] data -> data
I0117 19:40:23.781337 35429 net.cpp:408] data -> label
I0117 19:40:23.781836 35429 video_data_layer.cpp:39] Opening file /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/train-input-fb.txt
I0117 19:40:23.807802 35429 video_data_layer.cpp:53] Shuffling data
I0117 19:40:23.809062 35429 video_data_layer.cpp:58] A total of 13084 video chunks.
I0117 19:40:24.626497 35429 video_data_layer.cpp:98] output data size: 50,3,16,112,112
I0117 19:40:24.924572 35429 net.cpp:150] Setting up data
I0117 19:40:24.924685 35429 net.cpp:157] Top shape: 50 3 16 112 112 (30105600)
I0117 19:40:24.924762 35429 net.cpp:157] Top shape: 50 (50)
I0117 19:40:24.924777 35429 net.cpp:165] Memory required for data: 120422600
I0117 19:40:24.924799 35429 layer_factory.hpp:77] Creating layer conv1a
I0117 19:40:24.924850 35429 net.cpp:100] Creating Layer conv1a
I0117 19:40:24.924873 35429 net.cpp:434] conv1a <- data
I0117 19:40:24.924912 35429 net.cpp:408] conv1a -> conv1a
I0117 19:40:25.226249 35429 net.cpp:150] Setting up conv1a
I0117 19:40:25.226323 35429 net.cpp:157] Top shape: 50 64 16 112 112 (642252800)
I0117 19:40:25.226341 35429 net.cpp:165] Memory required for data: 2689433800
I0117 19:40:25.226377 35429 layer_factory.hpp:77] Creating layer relu1a
I0117 19:40:25.226410 35429 net.cpp:100] Creating Layer relu1a
I0117 19:40:25.226428 35429 net.cpp:434] relu1a <- conv1a
I0117 19:40:25.226447 35429 net.cpp:395] relu1a -> conv1a (in-place)
I0117 19:40:25.226814 35429 net.cpp:150] Setting up relu1a
I0117 19:40:25.226846 35429 net.cpp:157] Top shape: 50 64 16 112 112 (642252800)
I0117 19:40:25.226862 35429 net.cpp:165] Memory required for data: 5258445000
I0117 19:40:25.226876 35429 layer_factory.hpp:77] Creating layer pool1
I0117 19:40:25.226900 35429 net.cpp:100] Creating Layer pool1
I0117 19:40:25.226917 35429 net.cpp:434] pool1 <- conv1a
I0117 19:40:25.226935 35429 net.cpp:408] pool1 -> pool1
I0117 19:40:25.227198 35429 net.cpp:150] Setting up pool1
I0117 19:40:25.227229 35429 net.cpp:157] Top shape: 50 64 16 56 56 (160563200)
I0117 19:40:25.227244 35429 net.cpp:165] Memory required for data: 5900697800
I0117 19:40:25.227258 35429 layer_factory.hpp:77] Creating layer conv2a
I0117 19:40:25.227284 35429 net.cpp:100] Creating Layer conv2a
I0117 19:40:25.227301 35429 net.cpp:434] conv2a <- pool1
I0117 19:40:25.227321 35429 net.cpp:408] conv2a -> conv2a
I0117 19:40:25.233341 35429 net.cpp:150] Setting up conv2a
I0117 19:40:25.233377 35429 net.cpp:157] Top shape: 50 128 16 56 56 (321126400)
I0117 19:40:25.233393 35429 net.cpp:165] Memory required for data: 7185203400
I0117 19:40:25.233417 35429 layer_factory.hpp:77] Creating layer relu2a
I0117 19:40:25.233435 35429 net.cpp:100] Creating Layer relu2a
I0117 19:40:25.233451 35429 net.cpp:434] relu2a <- conv2a
I0117 19:40:25.233467 35429 net.cpp:395] relu2a -> conv2a (in-place)
I0117 19:40:25.233674 35429 net.cpp:150] Setting up relu2a
I0117 19:40:25.233703 35429 net.cpp:157] Top shape: 50 128 16 56 56 (321126400)
I0117 19:40:25.233717 35429 net.cpp:165] Memory required for data: 8469709000
I0117 19:40:25.233732 35429 layer_factory.hpp:77] Creating layer pool2
I0117 19:40:25.233752 35429 net.cpp:100] Creating Layer pool2
I0117 19:40:25.233768 35429 net.cpp:434] pool2 <- conv2a
I0117 19:40:25.233786 35429 net.cpp:408] pool2 -> pool2
I0117 19:40:25.234163 35429 net.cpp:150] Setting up pool2
I0117 19:40:25.234195 35429 net.cpp:157] Top shape: 50 128 8 28 28 (40140800)
I0117 19:40:25.234211 35429 net.cpp:165] Memory required for data: 8630272200
I0117 19:40:25.234227 35429 layer_factory.hpp:77] Creating layer conv3a
I0117 19:40:25.234251 35429 net.cpp:100] Creating Layer conv3a
I0117 19:40:25.234266 35429 net.cpp:434] conv3a <- pool2
I0117 19:40:25.234285 35429 net.cpp:408] conv3a -> conv3a
I0117 19:40:25.252833 35429 net.cpp:150] Setting up conv3a
I0117 19:40:25.252871 35429 net.cpp:157] Top shape: 50 256 8 28 28 (80281600)
I0117 19:40:25.252887 35429 net.cpp:165] Memory required for data: 8951398600
I0117 19:40:25.252908 35429 layer_factory.hpp:77] Creating layer relu3a
I0117 19:40:25.252933 35429 net.cpp:100] Creating Layer relu3a
I0117 19:40:25.252950 35429 net.cpp:434] relu3a <- conv3a
I0117 19:40:25.252969 35429 net.cpp:395] relu3a -> conv3a (in-place)
I0117 19:40:25.253187 35429 net.cpp:150] Setting up relu3a
I0117 19:40:25.253219 35429 net.cpp:157] Top shape: 50 256 8 28 28 (80281600)
I0117 19:40:25.253235 35429 net.cpp:165] Memory required for data: 9272525000
I0117 19:40:25.253249 35429 layer_factory.hpp:77] Creating layer pool3
I0117 19:40:25.253270 35429 net.cpp:100] Creating Layer pool3
I0117 19:40:25.253340 35429 net.cpp:434] pool3 <- conv3a
I0117 19:40:25.253363 35429 net.cpp:408] pool3 -> pool3
I0117 19:40:25.253779 35429 net.cpp:150] Setting up pool3
I0117 19:40:25.253813 35429 net.cpp:157] Top shape: 50 256 4 14 14 (10035200)
I0117 19:40:25.253828 35429 net.cpp:165] Memory required for data: 9312665800
I0117 19:40:25.253842 35429 layer_factory.hpp:77] Creating layer conv4a
I0117 19:40:25.253867 35429 net.cpp:100] Creating Layer conv4a
I0117 19:40:25.253885 35429 net.cpp:434] conv4a <- pool3
I0117 19:40:25.253907 35429 net.cpp:408] conv4a -> conv4a
I0117 19:40:25.290261 35429 net.cpp:150] Setting up conv4a
I0117 19:40:25.290297 35429 net.cpp:157] Top shape: 50 256 4 14 14 (10035200)
I0117 19:40:25.290313 35429 net.cpp:165] Memory required for data: 9352806600
I0117 19:40:25.290331 35429 layer_factory.hpp:77] Creating layer relu4a
I0117 19:40:25.290357 35429 net.cpp:100] Creating Layer relu4a
I0117 19:40:25.290375 35429 net.cpp:434] relu4a <- conv4a
I0117 19:40:25.290393 35429 net.cpp:395] relu4a -> conv4a (in-place)
I0117 19:40:25.290623 35429 net.cpp:150] Setting up relu4a
I0117 19:40:25.290653 35429 net.cpp:157] Top shape: 50 256 4 14 14 (10035200)
I0117 19:40:25.290668 35429 net.cpp:165] Memory required for data: 9392947400
I0117 19:40:25.290683 35429 layer_factory.hpp:77] Creating layer pool4
I0117 19:40:25.290707 35429 net.cpp:100] Creating Layer pool4
I0117 19:40:25.290724 35429 net.cpp:434] pool4 <- conv4a
I0117 19:40:25.290742 35429 net.cpp:408] pool4 -> pool4
I0117 19:40:25.291141 35429 net.cpp:150] Setting up pool4
I0117 19:40:25.291174 35429 net.cpp:157] Top shape: 50 256 2 7 7 (1254400)
I0117 19:40:25.291189 35429 net.cpp:165] Memory required for data: 9397965000
I0117 19:40:25.291203 35429 layer_factory.hpp:77] Creating layer conv5a
I0117 19:40:25.291231 35429 net.cpp:100] Creating Layer conv5a
I0117 19:40:25.291249 35429 net.cpp:434] conv5a <- pool4
I0117 19:40:25.291268 35429 net.cpp:408] conv5a -> conv5a
I0117 19:40:25.326845 35429 net.cpp:150] Setting up conv5a
I0117 19:40:25.326884 35429 net.cpp:157] Top shape: 50 256 2 7 7 (1254400)
I0117 19:40:25.326901 35429 net.cpp:165] Memory required for data: 9402982600
I0117 19:40:25.326925 35429 layer_factory.hpp:77] Creating layer relu5a
I0117 19:40:25.326944 35429 net.cpp:100] Creating Layer relu5a
I0117 19:40:25.326961 35429 net.cpp:434] relu5a <- conv5a
I0117 19:40:25.326978 35429 net.cpp:395] relu5a -> conv5a (in-place)
I0117 19:40:25.327337 35429 net.cpp:150] Setting up relu5a
I0117 19:40:25.327369 35429 net.cpp:157] Top shape: 50 256 2 7 7 (1254400)
I0117 19:40:25.327385 35429 net.cpp:165] Memory required for data: 9408000200
I0117 19:40:25.327399 35429 layer_factory.hpp:77] Creating layer pool5
I0117 19:40:25.327419 35429 net.cpp:100] Creating Layer pool5
I0117 19:40:25.327435 35429 net.cpp:434] pool5 <- conv5a
I0117 19:40:25.327456 35429 net.cpp:408] pool5 -> pool5
I0117 19:40:25.327865 35429 net.cpp:150] Setting up pool5
I0117 19:40:25.327898 35429 net.cpp:157] Top shape: 50 256 1 4 4 (204800)
I0117 19:40:25.327913 35429 net.cpp:165] Memory required for data: 9408819400
I0117 19:40:25.327927 35429 layer_factory.hpp:77] Creating layer fc6
I0117 19:40:25.327960 35429 net.cpp:100] Creating Layer fc6
I0117 19:40:25.327978 35429 net.cpp:434] fc6 <- pool5
I0117 19:40:25.328001 35429 net.cpp:408] fc6 -> fc6
I0117 19:40:25.487886 35429 net.cpp:150] Setting up fc6
I0117 19:40:25.487967 35429 net.cpp:157] Top shape: 50 2048 (102400)
I0117 19:40:25.487982 35429 net.cpp:165] Memory required for data: 9409229000
I0117 19:40:25.488003 35429 layer_factory.hpp:77] Creating layer relu6
I0117 19:40:25.488028 35429 net.cpp:100] Creating Layer relu6
I0117 19:40:25.488042 35429 net.cpp:434] relu6 <- fc6
I0117 19:40:25.488059 35429 net.cpp:395] relu6 -> fc6 (in-place)
I0117 19:40:25.488312 35429 net.cpp:150] Setting up relu6
I0117 19:40:25.488337 35429 net.cpp:157] Top shape: 50 2048 (102400)
I0117 19:40:25.488351 35429 net.cpp:165] Memory required for data: 9409638600
I0117 19:40:25.488364 35429 layer_factory.hpp:77] Creating layer fc7
I0117 19:40:25.488384 35429 net.cpp:100] Creating Layer fc7
I0117 19:40:25.488446 35429 net.cpp:434] fc7 <- fc6
I0117 19:40:25.488469 35429 net.cpp:408] fc7 -> fc7
I0117 19:40:25.558805 35429 net.cpp:150] Setting up fc7
I0117 19:40:25.558838 35429 net.cpp:157] Top shape: 50 2048 (102400)
I0117 19:40:25.558852 35429 net.cpp:165] Memory required for data: 9410048200
I0117 19:40:25.558868 35429 layer_factory.hpp:77] Creating layer relu7
I0117 19:40:25.558884 35429 net.cpp:100] Creating Layer relu7
I0117 19:40:25.558897 35429 net.cpp:434] relu7 <- fc7
I0117 19:40:25.558912 35429 net.cpp:395] relu7 -> fc7 (in-place)
I0117 19:40:25.559254 35429 net.cpp:150] Setting up relu7
I0117 19:40:25.559283 35429 net.cpp:157] Top shape: 50 2048 (102400)
I0117 19:40:25.559298 35429 net.cpp:165] Memory required for data: 9410457800
I0117 19:40:25.559310 35429 layer_factory.hpp:77] Creating layer my-fc8
I0117 19:40:25.559329 35429 net.cpp:100] Creating Layer my-fc8
I0117 19:40:25.559341 35429 net.cpp:434] my-fc8 <- fc7
I0117 19:40:25.559360 35429 net.cpp:408] my-fc8 -> fc8
I0117 19:40:25.559551 35429 net.cpp:150] Setting up my-fc8
I0117 19:40:25.559576 35429 net.cpp:157] Top shape: 50 2 (100)
I0117 19:40:25.559588 35429 net.cpp:165] Memory required for data: 9410458200
I0117 19:40:25.559604 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:25.559630 35429 net.cpp:100] Creating Layer loss
I0117 19:40:25.559645 35429 net.cpp:434] loss <- fc8
I0117 19:40:25.559659 35429 net.cpp:434] loss <- label
I0117 19:40:25.559677 35429 net.cpp:408] loss -> loss
I0117 19:40:25.559706 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:25.560006 35429 net.cpp:150] Setting up loss
I0117 19:40:25.560034 35429 net.cpp:157] Top shape: (1)
I0117 19:40:25.560046 35429 net.cpp:160]     with loss weight 1
I0117 19:40:25.560091 35429 net.cpp:165] Memory required for data: 9410458204
I0117 19:40:25.560104 35429 net.cpp:226] loss needs backward computation.
I0117 19:40:25.560117 35429 net.cpp:226] my-fc8 needs backward computation.
I0117 19:40:25.560129 35429 net.cpp:226] relu7 needs backward computation.
I0117 19:40:25.560142 35429 net.cpp:226] fc7 needs backward computation.
I0117 19:40:25.560154 35429 net.cpp:226] relu6 needs backward computation.
I0117 19:40:25.560166 35429 net.cpp:226] fc6 needs backward computation.
I0117 19:40:25.560178 35429 net.cpp:226] pool5 needs backward computation.
I0117 19:40:25.560189 35429 net.cpp:226] relu5a needs backward computation.
I0117 19:40:25.560202 35429 net.cpp:226] conv5a needs backward computation.
I0117 19:40:25.560214 35429 net.cpp:226] pool4 needs backward computation.
I0117 19:40:25.560227 35429 net.cpp:226] relu4a needs backward computation.
I0117 19:40:25.560238 35429 net.cpp:226] conv4a needs backward computation.
I0117 19:40:25.560250 35429 net.cpp:226] pool3 needs backward computation.
I0117 19:40:25.560263 35429 net.cpp:226] relu3a needs backward computation.
I0117 19:40:25.560276 35429 net.cpp:226] conv3a needs backward computation.
I0117 19:40:25.560287 35429 net.cpp:226] pool2 needs backward computation.
I0117 19:40:25.560300 35429 net.cpp:226] relu2a needs backward computation.
I0117 19:40:25.560312 35429 net.cpp:226] conv2a needs backward computation.
I0117 19:40:25.560323 35429 net.cpp:226] pool1 needs backward computation.
I0117 19:40:25.560335 35429 net.cpp:226] relu1a needs backward computation.
I0117 19:40:25.560348 35429 net.cpp:226] conv1a needs backward computation.
I0117 19:40:25.560360 35429 net.cpp:228] data does not need backward computation.
I0117 19:40:25.560371 35429 net.cpp:270] This network produces output loss
I0117 19:40:25.560398 35429 net.cpp:283] Network initialization done.
I0117 19:40:25.561913 35429 solver.cpp:181] Creating test net (#0) specified by net file: /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/c3d_arrow_train_fb_no_drop.prototxt
I0117 19:40:25.561988 35429 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0117 19:40:25.562012 35429 net.cpp:358] The NetState did not contain stage 'test-on-val' specified by a rule in layer data
I0117 19:40:25.562309 35429 net.cpp:58] Initializing net from parameters: 
name: "c3d_arrow"
state {
  phase: TEST
  stage: "test-on-train"
}
layer {
  name: "data"
  type: "VideoData"
  top: "data"
  top: "label"
  include {
    phase: TEST
    stage: "test-on-train"
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_value: 90
    mean_value: 98
    mean_value: 102
  }
  video_data_param {
    source: "/workdir/hassony/new-video/video-caffe/examples/c3d_arrow/train-input-fb.txt"
    batch_size: 40
    shuffle: true
    new_length: 16
    new_height: 128
    new_width: 171
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "my-fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "prob"
  bottom: "label"
  top: "accuracy/top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0117 19:40:25.562490 35429 layer_factory.hpp:77] Creating layer data
I0117 19:40:25.562526 35429 net.cpp:100] Creating Layer data
I0117 19:40:25.562544 35429 net.cpp:408] data -> data
I0117 19:40:25.562566 35429 net.cpp:408] data -> label
I0117 19:40:25.562587 35429 video_data_layer.cpp:39] Opening file /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/train-input-fb.txt
I0117 19:40:25.569494 35429 video_data_layer.cpp:53] Shuffling data
I0117 19:40:25.570565 35429 video_data_layer.cpp:58] A total of 13084 video chunks.
I0117 19:40:26.263125 35429 video_data_layer.cpp:98] output data size: 40,3,16,112,112
I0117 19:40:26.463965 35429 net.cpp:150] Setting up data
I0117 19:40:26.464040 35429 net.cpp:157] Top shape: 40 3 16 112 112 (24084480)
I0117 19:40:26.464057 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:26.464068 35429 net.cpp:165] Memory required for data: 96338080
I0117 19:40:26.464085 35429 layer_factory.hpp:77] Creating layer label_data_1_split
I0117 19:40:26.464118 35429 net.cpp:100] Creating Layer label_data_1_split
I0117 19:40:26.464133 35429 net.cpp:434] label_data_1_split <- label
I0117 19:40:26.464151 35429 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0117 19:40:26.464172 35429 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0117 19:40:26.464248 35429 net.cpp:150] Setting up label_data_1_split
I0117 19:40:26.464270 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:26.464284 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:26.464294 35429 net.cpp:165] Memory required for data: 96338400
I0117 19:40:26.464308 35429 layer_factory.hpp:77] Creating layer conv1a
I0117 19:40:26.464331 35429 net.cpp:100] Creating Layer conv1a
I0117 19:40:26.464345 35429 net.cpp:434] conv1a <- data
I0117 19:40:26.464411 35429 net.cpp:408] conv1a -> conv1a
I0117 19:40:26.466397 35429 net.cpp:150] Setting up conv1a
I0117 19:40:26.466429 35429 net.cpp:157] Top shape: 40 64 16 112 112 (513802240)
I0117 19:40:26.466444 35429 net.cpp:165] Memory required for data: 2151547360
I0117 19:40:26.466464 35429 layer_factory.hpp:77] Creating layer relu1a
I0117 19:40:26.466488 35429 net.cpp:100] Creating Layer relu1a
I0117 19:40:26.466505 35429 net.cpp:434] relu1a <- conv1a
I0117 19:40:26.466521 35429 net.cpp:395] relu1a -> conv1a (in-place)
I0117 19:40:26.466835 35429 net.cpp:150] Setting up relu1a
I0117 19:40:26.466862 35429 net.cpp:157] Top shape: 40 64 16 112 112 (513802240)
I0117 19:40:26.466874 35429 net.cpp:165] Memory required for data: 4206756320
I0117 19:40:26.466887 35429 layer_factory.hpp:77] Creating layer pool1
I0117 19:40:26.466907 35429 net.cpp:100] Creating Layer pool1
I0117 19:40:26.466922 35429 net.cpp:434] pool1 <- conv1a
I0117 19:40:26.466938 35429 net.cpp:408] pool1 -> pool1
I0117 19:40:26.467152 35429 net.cpp:150] Setting up pool1
I0117 19:40:26.467177 35429 net.cpp:157] Top shape: 40 64 16 56 56 (128450560)
I0117 19:40:26.467191 35429 net.cpp:165] Memory required for data: 4720558560
I0117 19:40:26.467203 35429 layer_factory.hpp:77] Creating layer conv2a
I0117 19:40:26.467222 35429 net.cpp:100] Creating Layer conv2a
I0117 19:40:26.467236 35429 net.cpp:434] conv2a <- pool1
I0117 19:40:26.467252 35429 net.cpp:408] conv2a -> conv2a
I0117 19:40:26.471967 35429 net.cpp:150] Setting up conv2a
I0117 19:40:26.471997 35429 net.cpp:157] Top shape: 40 128 16 56 56 (256901120)
I0117 19:40:26.472012 35429 net.cpp:165] Memory required for data: 5748163040
I0117 19:40:26.472030 35429 layer_factory.hpp:77] Creating layer relu2a
I0117 19:40:26.472048 35429 net.cpp:100] Creating Layer relu2a
I0117 19:40:26.472061 35429 net.cpp:434] relu2a <- conv2a
I0117 19:40:26.472075 35429 net.cpp:395] relu2a -> conv2a (in-place)
I0117 19:40:26.472254 35429 net.cpp:150] Setting up relu2a
I0117 19:40:26.472280 35429 net.cpp:157] Top shape: 40 128 16 56 56 (256901120)
I0117 19:40:26.472291 35429 net.cpp:165] Memory required for data: 6775767520
I0117 19:40:26.472304 35429 layer_factory.hpp:77] Creating layer pool2
I0117 19:40:26.472322 35429 net.cpp:100] Creating Layer pool2
I0117 19:40:26.472334 35429 net.cpp:434] pool2 <- conv2a
I0117 19:40:26.472350 35429 net.cpp:408] pool2 -> pool2
I0117 19:40:26.472702 35429 net.cpp:150] Setting up pool2
I0117 19:40:26.472729 35429 net.cpp:157] Top shape: 40 128 8 28 28 (32112640)
I0117 19:40:26.472741 35429 net.cpp:165] Memory required for data: 6904218080
I0117 19:40:26.472754 35429 layer_factory.hpp:77] Creating layer conv3a
I0117 19:40:26.472775 35429 net.cpp:100] Creating Layer conv3a
I0117 19:40:26.472790 35429 net.cpp:434] conv3a <- pool2
I0117 19:40:26.472805 35429 net.cpp:408] conv3a -> conv3a
I0117 19:40:26.488579 35429 net.cpp:150] Setting up conv3a
I0117 19:40:26.488608 35429 net.cpp:157] Top shape: 40 256 8 28 28 (64225280)
I0117 19:40:26.488623 35429 net.cpp:165] Memory required for data: 7161119200
I0117 19:40:26.488642 35429 layer_factory.hpp:77] Creating layer relu3a
I0117 19:40:26.488661 35429 net.cpp:100] Creating Layer relu3a
I0117 19:40:26.488674 35429 net.cpp:434] relu3a <- conv3a
I0117 19:40:26.488688 35429 net.cpp:395] relu3a -> conv3a (in-place)
I0117 19:40:26.488867 35429 net.cpp:150] Setting up relu3a
I0117 19:40:26.488893 35429 net.cpp:157] Top shape: 40 256 8 28 28 (64225280)
I0117 19:40:26.488905 35429 net.cpp:165] Memory required for data: 7418020320
I0117 19:40:26.488919 35429 layer_factory.hpp:77] Creating layer pool3
I0117 19:40:26.488935 35429 net.cpp:100] Creating Layer pool3
I0117 19:40:26.488950 35429 net.cpp:434] pool3 <- conv3a
I0117 19:40:26.488965 35429 net.cpp:408] pool3 -> pool3
I0117 19:40:26.489310 35429 net.cpp:150] Setting up pool3
I0117 19:40:26.489336 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:26.489348 35429 net.cpp:165] Memory required for data: 7450132960
I0117 19:40:26.489362 35429 layer_factory.hpp:77] Creating layer conv4a
I0117 19:40:26.489406 35429 net.cpp:100] Creating Layer conv4a
I0117 19:40:26.489423 35429 net.cpp:434] conv4a <- pool3
I0117 19:40:26.489440 35429 net.cpp:408] conv4a -> conv4a
I0117 19:40:26.520043 35429 net.cpp:150] Setting up conv4a
I0117 19:40:26.520073 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:26.520087 35429 net.cpp:165] Memory required for data: 7482245600
I0117 19:40:26.520103 35429 layer_factory.hpp:77] Creating layer relu4a
I0117 19:40:26.520120 35429 net.cpp:100] Creating Layer relu4a
I0117 19:40:26.520133 35429 net.cpp:434] relu4a <- conv4a
I0117 19:40:26.520149 35429 net.cpp:395] relu4a -> conv4a (in-place)
I0117 19:40:26.520325 35429 net.cpp:150] Setting up relu4a
I0117 19:40:26.520350 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:26.520364 35429 net.cpp:165] Memory required for data: 7514358240
I0117 19:40:26.520375 35429 layer_factory.hpp:77] Creating layer pool4
I0117 19:40:26.520392 35429 net.cpp:100] Creating Layer pool4
I0117 19:40:26.520406 35429 net.cpp:434] pool4 <- conv4a
I0117 19:40:26.520421 35429 net.cpp:408] pool4 -> pool4
I0117 19:40:26.520773 35429 net.cpp:150] Setting up pool4
I0117 19:40:26.520802 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:26.520815 35429 net.cpp:165] Memory required for data: 7518372320
I0117 19:40:26.520828 35429 layer_factory.hpp:77] Creating layer conv5a
I0117 19:40:26.520848 35429 net.cpp:100] Creating Layer conv5a
I0117 19:40:26.520862 35429 net.cpp:434] conv5a <- pool4
I0117 19:40:26.520880 35429 net.cpp:408] conv5a -> conv5a
I0117 19:40:26.551185 35429 net.cpp:150] Setting up conv5a
I0117 19:40:26.551223 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:26.551236 35429 net.cpp:165] Memory required for data: 7522386400
I0117 19:40:26.551256 35429 layer_factory.hpp:77] Creating layer relu5a
I0117 19:40:26.551273 35429 net.cpp:100] Creating Layer relu5a
I0117 19:40:26.551286 35429 net.cpp:434] relu5a <- conv5a
I0117 19:40:26.551302 35429 net.cpp:395] relu5a -> conv5a (in-place)
I0117 19:40:26.551614 35429 net.cpp:150] Setting up relu5a
I0117 19:40:26.551640 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:26.551653 35429 net.cpp:165] Memory required for data: 7526400480
I0117 19:40:26.551666 35429 layer_factory.hpp:77] Creating layer pool5
I0117 19:40:26.551687 35429 net.cpp:100] Creating Layer pool5
I0117 19:40:26.551699 35429 net.cpp:434] pool5 <- conv5a
I0117 19:40:26.551717 35429 net.cpp:408] pool5 -> pool5
I0117 19:40:26.552062 35429 net.cpp:150] Setting up pool5
I0117 19:40:26.552088 35429 net.cpp:157] Top shape: 40 256 1 4 4 (163840)
I0117 19:40:26.552101 35429 net.cpp:165] Memory required for data: 7527055840
I0117 19:40:26.552114 35429 layer_factory.hpp:77] Creating layer fc6
I0117 19:40:26.552134 35429 net.cpp:100] Creating Layer fc6
I0117 19:40:26.552146 35429 net.cpp:434] fc6 <- pool5
I0117 19:40:26.552162 35429 net.cpp:408] fc6 -> fc6
I0117 19:40:26.694793 35429 net.cpp:150] Setting up fc6
I0117 19:40:26.694865 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:26.694880 35429 net.cpp:165] Memory required for data: 7527383520
I0117 19:40:26.694900 35429 layer_factory.hpp:77] Creating layer relu6
I0117 19:40:26.694921 35429 net.cpp:100] Creating Layer relu6
I0117 19:40:26.694936 35429 net.cpp:434] relu6 <- fc6
I0117 19:40:26.694953 35429 net.cpp:395] relu6 -> fc6 (in-place)
I0117 19:40:26.695204 35429 net.cpp:150] Setting up relu6
I0117 19:40:26.695228 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:26.695241 35429 net.cpp:165] Memory required for data: 7527711200
I0117 19:40:26.695255 35429 layer_factory.hpp:77] Creating layer fc7
I0117 19:40:26.695273 35429 net.cpp:100] Creating Layer fc7
I0117 19:40:26.695287 35429 net.cpp:434] fc7 <- fc6
I0117 19:40:26.695304 35429 net.cpp:408] fc7 -> fc7
I0117 19:40:26.766618 35429 net.cpp:150] Setting up fc7
I0117 19:40:26.766647 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:26.766660 35429 net.cpp:165] Memory required for data: 7528038880
I0117 19:40:26.766677 35429 layer_factory.hpp:77] Creating layer relu7
I0117 19:40:26.766741 35429 net.cpp:100] Creating Layer relu7
I0117 19:40:26.766755 35429 net.cpp:434] relu7 <- fc7
I0117 19:40:26.766770 35429 net.cpp:395] relu7 -> fc7 (in-place)
I0117 19:40:26.767117 35429 net.cpp:150] Setting up relu7
I0117 19:40:26.767145 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:26.767158 35429 net.cpp:165] Memory required for data: 7528366560
I0117 19:40:26.767169 35429 layer_factory.hpp:77] Creating layer my-fc8
I0117 19:40:26.767186 35429 net.cpp:100] Creating Layer my-fc8
I0117 19:40:26.767199 35429 net.cpp:434] my-fc8 <- fc7
I0117 19:40:26.767216 35429 net.cpp:408] my-fc8 -> fc8
I0117 19:40:26.767407 35429 net.cpp:150] Setting up my-fc8
I0117 19:40:26.767431 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:26.767443 35429 net.cpp:165] Memory required for data: 7528366880
I0117 19:40:26.767458 35429 layer_factory.hpp:77] Creating layer fc8_my-fc8_0_split
I0117 19:40:26.767475 35429 net.cpp:100] Creating Layer fc8_my-fc8_0_split
I0117 19:40:26.767495 35429 net.cpp:434] fc8_my-fc8_0_split <- fc8
I0117 19:40:26.767513 35429 net.cpp:408] fc8_my-fc8_0_split -> fc8_my-fc8_0_split_0
I0117 19:40:26.767529 35429 net.cpp:408] fc8_my-fc8_0_split -> fc8_my-fc8_0_split_1
I0117 19:40:26.767582 35429 net.cpp:150] Setting up fc8_my-fc8_0_split
I0117 19:40:26.767604 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:26.767617 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:26.767628 35429 net.cpp:165] Memory required for data: 7528367520
I0117 19:40:26.767639 35429 layer_factory.hpp:77] Creating layer prob
I0117 19:40:26.767657 35429 net.cpp:100] Creating Layer prob
I0117 19:40:26.767670 35429 net.cpp:434] prob <- fc8_my-fc8_0_split_0
I0117 19:40:26.767685 35429 net.cpp:408] prob -> prob
I0117 19:40:26.767930 35429 net.cpp:150] Setting up prob
I0117 19:40:26.767954 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:26.767966 35429 net.cpp:165] Memory required for data: 7528367840
I0117 19:40:26.767978 35429 layer_factory.hpp:77] Creating layer accuracy
I0117 19:40:26.768003 35429 net.cpp:100] Creating Layer accuracy
I0117 19:40:26.768016 35429 net.cpp:434] accuracy <- prob
I0117 19:40:26.768029 35429 net.cpp:434] accuracy <- label_data_1_split_0
I0117 19:40:26.768044 35429 net.cpp:408] accuracy -> accuracy/top-1
I0117 19:40:26.768067 35429 net.cpp:150] Setting up accuracy
I0117 19:40:26.768085 35429 net.cpp:157] Top shape: (1)
I0117 19:40:26.768096 35429 net.cpp:165] Memory required for data: 7528367844
I0117 19:40:26.768108 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:26.768122 35429 net.cpp:100] Creating Layer loss
I0117 19:40:26.768136 35429 net.cpp:434] loss <- fc8_my-fc8_0_split_1
I0117 19:40:26.768149 35429 net.cpp:434] loss <- label_data_1_split_1
I0117 19:40:26.768162 35429 net.cpp:408] loss -> loss
I0117 19:40:26.768182 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:26.768599 35429 net.cpp:150] Setting up loss
I0117 19:40:26.768626 35429 net.cpp:157] Top shape: (1)
I0117 19:40:26.768638 35429 net.cpp:160]     with loss weight 1
I0117 19:40:26.768659 35429 net.cpp:165] Memory required for data: 7528367848
I0117 19:40:26.768671 35429 net.cpp:226] loss needs backward computation.
I0117 19:40:26.768684 35429 net.cpp:228] accuracy does not need backward computation.
I0117 19:40:26.768697 35429 net.cpp:228] prob does not need backward computation.
I0117 19:40:26.768709 35429 net.cpp:226] fc8_my-fc8_0_split needs backward computation.
I0117 19:40:26.768723 35429 net.cpp:226] my-fc8 needs backward computation.
I0117 19:40:26.768733 35429 net.cpp:226] relu7 needs backward computation.
I0117 19:40:26.768744 35429 net.cpp:226] fc7 needs backward computation.
I0117 19:40:26.768755 35429 net.cpp:226] relu6 needs backward computation.
I0117 19:40:26.768766 35429 net.cpp:226] fc6 needs backward computation.
I0117 19:40:26.768777 35429 net.cpp:226] pool5 needs backward computation.
I0117 19:40:26.768790 35429 net.cpp:226] relu5a needs backward computation.
I0117 19:40:26.768800 35429 net.cpp:226] conv5a needs backward computation.
I0117 19:40:26.768841 35429 net.cpp:226] pool4 needs backward computation.
I0117 19:40:26.768856 35429 net.cpp:226] relu4a needs backward computation.
I0117 19:40:26.768867 35429 net.cpp:226] conv4a needs backward computation.
I0117 19:40:26.768878 35429 net.cpp:226] pool3 needs backward computation.
I0117 19:40:26.768890 35429 net.cpp:226] relu3a needs backward computation.
I0117 19:40:26.768903 35429 net.cpp:226] conv3a needs backward computation.
I0117 19:40:26.768914 35429 net.cpp:226] pool2 needs backward computation.
I0117 19:40:26.768926 35429 net.cpp:226] relu2a needs backward computation.
I0117 19:40:26.768937 35429 net.cpp:226] conv2a needs backward computation.
I0117 19:40:26.768949 35429 net.cpp:226] pool1 needs backward computation.
I0117 19:40:26.768961 35429 net.cpp:226] relu1a needs backward computation.
I0117 19:40:26.768972 35429 net.cpp:226] conv1a needs backward computation.
I0117 19:40:26.768985 35429 net.cpp:228] label_data_1_split does not need backward computation.
I0117 19:40:26.768997 35429 net.cpp:228] data does not need backward computation.
I0117 19:40:26.769007 35429 net.cpp:270] This network produces output accuracy/top-1
I0117 19:40:26.769021 35429 net.cpp:270] This network produces output loss
I0117 19:40:26.769044 35429 net.cpp:283] Network initialization done.
I0117 19:40:26.769129 35429 solver.cpp:181] Creating test net (#1) specified by net file: /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/c3d_arrow_train_fb_no_drop.prototxt
I0117 19:40:26.769199 35429 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0117 19:40:26.769218 35429 net.cpp:358] The NetState did not contain stage 'test-on-train' specified by a rule in layer data
I0117 19:40:26.769506 35429 net.cpp:58] Initializing net from parameters: 
name: "c3d_arrow"
state {
  phase: TEST
  stage: "test-on-val"
}
layer {
  name: "data"
  type: "VideoData"
  top: "data"
  top: "label"
  include {
    phase: TEST
    stage: "test-on-val"
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_value: 90
    mean_value: 98
    mean_value: 102
  }
  video_data_param {
    source: "/workdir/hassony/new-video/video-caffe/examples/c3d_arrow/test-input-fb.txt"
    batch_size: 40
    shuffle: false
    new_length: 16
    new_height: 128
    new_width: 171
  }
}
layer {
  name: "conv1a"
  type: "NdConvolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "NdPooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 1
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 1
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv2a"
  type: "NdConvolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "NdPooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv3a"
  type: "NdConvolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "pool3"
  type: "NdPooling"
  bottom: "conv3a"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv4a"
  type: "NdConvolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "pool4"
  type: "NdPooling"
  bottom: "conv4a"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "conv5a"
  type: "NdConvolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
    pad_shape {
      dim: 1
      dim: 1
      dim: 1
    }
    kernel_shape {
      dim: 3
      dim: 3
      dim: 3
    }
    stride_shape {
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "pool5"
  type: "NdPooling"
  bottom: "conv5a"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_shape {
      dim: 2
      dim: 2
      dim: 2
    }
    stride_shape {
      dim: 2
      dim: 2
      dim: 2
    }
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "my-fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "prob"
  bottom: "label"
  top: "accuracy/top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0117 19:40:26.769654 35429 layer_factory.hpp:77] Creating layer data
I0117 19:40:26.769716 35429 net.cpp:100] Creating Layer data
I0117 19:40:26.769734 35429 net.cpp:408] data -> data
I0117 19:40:26.769753 35429 net.cpp:408] data -> label
I0117 19:40:26.769774 35429 video_data_layer.cpp:39] Opening file /workdir/hassony/new-video/video-caffe/examples/c3d_arrow/test-input-fb.txt
I0117 19:40:26.782894 35429 video_data_layer.cpp:58] A total of 3366 video chunks.
I0117 19:40:27.282577 35429 video_data_layer.cpp:98] output data size: 40,3,16,112,112
I0117 19:40:27.484195 35429 net.cpp:150] Setting up data
I0117 19:40:27.484268 35429 net.cpp:157] Top shape: 40 3 16 112 112 (24084480)
I0117 19:40:27.484285 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:27.484297 35429 net.cpp:165] Memory required for data: 96338080
I0117 19:40:27.484313 35429 layer_factory.hpp:77] Creating layer label_data_1_split
I0117 19:40:27.484338 35429 net.cpp:100] Creating Layer label_data_1_split
I0117 19:40:27.484354 35429 net.cpp:434] label_data_1_split <- label
I0117 19:40:27.484374 35429 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0117 19:40:27.484393 35429 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0117 19:40:27.484469 35429 net.cpp:150] Setting up label_data_1_split
I0117 19:40:27.484499 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:27.484514 35429 net.cpp:157] Top shape: 40 (40)
I0117 19:40:27.484525 35429 net.cpp:165] Memory required for data: 96338400
I0117 19:40:27.484537 35429 layer_factory.hpp:77] Creating layer conv1a
I0117 19:40:27.484563 35429 net.cpp:100] Creating Layer conv1a
I0117 19:40:27.484577 35429 net.cpp:434] conv1a <- data
I0117 19:40:27.484594 35429 net.cpp:408] conv1a -> conv1a
I0117 19:40:27.486467 35429 net.cpp:150] Setting up conv1a
I0117 19:40:27.486506 35429 net.cpp:157] Top shape: 40 64 16 112 112 (513802240)
I0117 19:40:27.486521 35429 net.cpp:165] Memory required for data: 2151547360
I0117 19:40:27.486543 35429 layer_factory.hpp:77] Creating layer relu1a
I0117 19:40:27.486562 35429 net.cpp:100] Creating Layer relu1a
I0117 19:40:27.486574 35429 net.cpp:434] relu1a <- conv1a
I0117 19:40:27.486589 35429 net.cpp:395] relu1a -> conv1a (in-place)
I0117 19:40:27.486913 35429 net.cpp:150] Setting up relu1a
I0117 19:40:27.486941 35429 net.cpp:157] Top shape: 40 64 16 112 112 (513802240)
I0117 19:40:27.486954 35429 net.cpp:165] Memory required for data: 4206756320
I0117 19:40:27.486966 35429 layer_factory.hpp:77] Creating layer pool1
I0117 19:40:27.486987 35429 net.cpp:100] Creating Layer pool1
I0117 19:40:27.487001 35429 net.cpp:434] pool1 <- conv1a
I0117 19:40:27.487017 35429 net.cpp:408] pool1 -> pool1
I0117 19:40:27.487385 35429 net.cpp:150] Setting up pool1
I0117 19:40:27.487413 35429 net.cpp:157] Top shape: 40 64 16 56 56 (128450560)
I0117 19:40:27.487426 35429 net.cpp:165] Memory required for data: 4720558560
I0117 19:40:27.487440 35429 layer_factory.hpp:77] Creating layer conv2a
I0117 19:40:27.487459 35429 net.cpp:100] Creating Layer conv2a
I0117 19:40:27.487473 35429 net.cpp:434] conv2a <- pool1
I0117 19:40:27.487498 35429 net.cpp:408] conv2a -> conv2a
I0117 19:40:27.492089 35429 net.cpp:150] Setting up conv2a
I0117 19:40:27.492120 35429 net.cpp:157] Top shape: 40 128 16 56 56 (256901120)
I0117 19:40:27.492135 35429 net.cpp:165] Memory required for data: 5748163040
I0117 19:40:27.492154 35429 layer_factory.hpp:77] Creating layer relu2a
I0117 19:40:27.492172 35429 net.cpp:100] Creating Layer relu2a
I0117 19:40:27.492185 35429 net.cpp:434] relu2a <- conv2a
I0117 19:40:27.492200 35429 net.cpp:395] relu2a -> conv2a (in-place)
I0117 19:40:27.492524 35429 net.cpp:150] Setting up relu2a
I0117 19:40:27.492552 35429 net.cpp:157] Top shape: 40 128 16 56 56 (256901120)
I0117 19:40:27.492563 35429 net.cpp:165] Memory required for data: 6775767520
I0117 19:40:27.492576 35429 layer_factory.hpp:77] Creating layer pool2
I0117 19:40:27.492594 35429 net.cpp:100] Creating Layer pool2
I0117 19:40:27.492607 35429 net.cpp:434] pool2 <- conv2a
I0117 19:40:27.492624 35429 net.cpp:408] pool2 -> pool2
I0117 19:40:27.492841 35429 net.cpp:150] Setting up pool2
I0117 19:40:27.492911 35429 net.cpp:157] Top shape: 40 128 8 28 28 (32112640)
I0117 19:40:27.492925 35429 net.cpp:165] Memory required for data: 6904218080
I0117 19:40:27.492938 35429 layer_factory.hpp:77] Creating layer conv3a
I0117 19:40:27.492959 35429 net.cpp:100] Creating Layer conv3a
I0117 19:40:27.492974 35429 net.cpp:434] conv3a <- pool2
I0117 19:40:27.492990 35429 net.cpp:408] conv3a -> conv3a
I0117 19:40:27.508833 35429 net.cpp:150] Setting up conv3a
I0117 19:40:27.508865 35429 net.cpp:157] Top shape: 40 256 8 28 28 (64225280)
I0117 19:40:27.508879 35429 net.cpp:165] Memory required for data: 7161119200
I0117 19:40:27.508899 35429 layer_factory.hpp:77] Creating layer relu3a
I0117 19:40:27.508916 35429 net.cpp:100] Creating Layer relu3a
I0117 19:40:27.508930 35429 net.cpp:434] relu3a <- conv3a
I0117 19:40:27.508944 35429 net.cpp:395] relu3a -> conv3a (in-place)
I0117 19:40:27.509254 35429 net.cpp:150] Setting up relu3a
I0117 19:40:27.509282 35429 net.cpp:157] Top shape: 40 256 8 28 28 (64225280)
I0117 19:40:27.509295 35429 net.cpp:165] Memory required for data: 7418020320
I0117 19:40:27.509308 35429 layer_factory.hpp:77] Creating layer pool3
I0117 19:40:27.509326 35429 net.cpp:100] Creating Layer pool3
I0117 19:40:27.509340 35429 net.cpp:434] pool3 <- conv3a
I0117 19:40:27.509356 35429 net.cpp:408] pool3 -> pool3
I0117 19:40:27.509578 35429 net.cpp:150] Setting up pool3
I0117 19:40:27.509604 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:27.509616 35429 net.cpp:165] Memory required for data: 7450132960
I0117 19:40:27.509629 35429 layer_factory.hpp:77] Creating layer conv4a
I0117 19:40:27.509647 35429 net.cpp:100] Creating Layer conv4a
I0117 19:40:27.509661 35429 net.cpp:434] conv4a <- pool3
I0117 19:40:27.509678 35429 net.cpp:408] conv4a -> conv4a
I0117 19:40:27.540210 35429 net.cpp:150] Setting up conv4a
I0117 19:40:27.540238 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:27.540252 35429 net.cpp:165] Memory required for data: 7482245600
I0117 19:40:27.540269 35429 layer_factory.hpp:77] Creating layer relu4a
I0117 19:40:27.540287 35429 net.cpp:100] Creating Layer relu4a
I0117 19:40:27.540299 35429 net.cpp:434] relu4a <- conv4a
I0117 19:40:27.540314 35429 net.cpp:395] relu4a -> conv4a (in-place)
I0117 19:40:27.540630 35429 net.cpp:150] Setting up relu4a
I0117 19:40:27.540657 35429 net.cpp:157] Top shape: 40 256 4 14 14 (8028160)
I0117 19:40:27.540669 35429 net.cpp:165] Memory required for data: 7514358240
I0117 19:40:27.540683 35429 layer_factory.hpp:77] Creating layer pool4
I0117 19:40:27.540699 35429 net.cpp:100] Creating Layer pool4
I0117 19:40:27.540714 35429 net.cpp:434] pool4 <- conv4a
I0117 19:40:27.540729 35429 net.cpp:408] pool4 -> pool4
I0117 19:40:27.540947 35429 net.cpp:150] Setting up pool4
I0117 19:40:27.540973 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:27.540985 35429 net.cpp:165] Memory required for data: 7518372320
I0117 19:40:27.540998 35429 layer_factory.hpp:77] Creating layer conv5a
I0117 19:40:27.541018 35429 net.cpp:100] Creating Layer conv5a
I0117 19:40:27.541033 35429 net.cpp:434] conv5a <- pool4
I0117 19:40:27.541049 35429 net.cpp:408] conv5a -> conv5a
I0117 19:40:27.571543 35429 net.cpp:150] Setting up conv5a
I0117 19:40:27.571578 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:27.571593 35429 net.cpp:165] Memory required for data: 7522386400
I0117 19:40:27.571612 35429 layer_factory.hpp:77] Creating layer relu5a
I0117 19:40:27.571630 35429 net.cpp:100] Creating Layer relu5a
I0117 19:40:27.571643 35429 net.cpp:434] relu5a <- conv5a
I0117 19:40:27.571660 35429 net.cpp:395] relu5a -> conv5a (in-place)
I0117 19:40:27.571966 35429 net.cpp:150] Setting up relu5a
I0117 19:40:27.571993 35429 net.cpp:157] Top shape: 40 256 2 7 7 (1003520)
I0117 19:40:27.572005 35429 net.cpp:165] Memory required for data: 7526400480
I0117 19:40:27.572017 35429 layer_factory.hpp:77] Creating layer pool5
I0117 19:40:27.572036 35429 net.cpp:100] Creating Layer pool5
I0117 19:40:27.572049 35429 net.cpp:434] pool5 <- conv5a
I0117 19:40:27.572091 35429 net.cpp:408] pool5 -> pool5
I0117 19:40:27.572310 35429 net.cpp:150] Setting up pool5
I0117 19:40:27.572336 35429 net.cpp:157] Top shape: 40 256 1 4 4 (163840)
I0117 19:40:27.572350 35429 net.cpp:165] Memory required for data: 7527055840
I0117 19:40:27.572361 35429 layer_factory.hpp:77] Creating layer fc6
I0117 19:40:27.572379 35429 net.cpp:100] Creating Layer fc6
I0117 19:40:27.572392 35429 net.cpp:434] fc6 <- pool5
I0117 19:40:27.572408 35429 net.cpp:408] fc6 -> fc6
I0117 19:40:27.715139 35429 net.cpp:150] Setting up fc6
I0117 19:40:27.715214 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:27.715227 35429 net.cpp:165] Memory required for data: 7527383520
I0117 19:40:27.715248 35429 layer_factory.hpp:77] Creating layer relu6
I0117 19:40:27.715268 35429 net.cpp:100] Creating Layer relu6
I0117 19:40:27.715283 35429 net.cpp:434] relu6 <- fc6
I0117 19:40:27.715301 35429 net.cpp:395] relu6 -> fc6 (in-place)
I0117 19:40:27.715729 35429 net.cpp:150] Setting up relu6
I0117 19:40:27.715756 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:27.715770 35429 net.cpp:165] Memory required for data: 7527711200
I0117 19:40:27.715782 35429 layer_factory.hpp:77] Creating layer fc7
I0117 19:40:27.715802 35429 net.cpp:100] Creating Layer fc7
I0117 19:40:27.715814 35429 net.cpp:434] fc7 <- fc6
I0117 19:40:27.715831 35429 net.cpp:408] fc7 -> fc7
I0117 19:40:27.787180 35429 net.cpp:150] Setting up fc7
I0117 19:40:27.787210 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:27.787223 35429 net.cpp:165] Memory required for data: 7528038880
I0117 19:40:27.787240 35429 layer_factory.hpp:77] Creating layer relu7
I0117 19:40:27.787256 35429 net.cpp:100] Creating Layer relu7
I0117 19:40:27.787268 35429 net.cpp:434] relu7 <- fc7
I0117 19:40:27.787284 35429 net.cpp:395] relu7 -> fc7 (in-place)
I0117 19:40:27.787485 35429 net.cpp:150] Setting up relu7
I0117 19:40:27.787511 35429 net.cpp:157] Top shape: 40 2048 (81920)
I0117 19:40:27.787524 35429 net.cpp:165] Memory required for data: 7528366560
I0117 19:40:27.787536 35429 layer_factory.hpp:77] Creating layer my-fc8
I0117 19:40:27.787554 35429 net.cpp:100] Creating Layer my-fc8
I0117 19:40:27.787567 35429 net.cpp:434] my-fc8 <- fc7
I0117 19:40:27.787585 35429 net.cpp:408] my-fc8 -> fc8
I0117 19:40:27.787782 35429 net.cpp:150] Setting up my-fc8
I0117 19:40:27.787806 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:27.787818 35429 net.cpp:165] Memory required for data: 7528366880
I0117 19:40:27.787833 35429 layer_factory.hpp:77] Creating layer fc8_my-fc8_0_split
I0117 19:40:27.787848 35429 net.cpp:100] Creating Layer fc8_my-fc8_0_split
I0117 19:40:27.787861 35429 net.cpp:434] fc8_my-fc8_0_split <- fc8
I0117 19:40:27.787876 35429 net.cpp:408] fc8_my-fc8_0_split -> fc8_my-fc8_0_split_0
I0117 19:40:27.787894 35429 net.cpp:408] fc8_my-fc8_0_split -> fc8_my-fc8_0_split_1
I0117 19:40:27.787948 35429 net.cpp:150] Setting up fc8_my-fc8_0_split
I0117 19:40:27.787971 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:27.787984 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:27.787994 35429 net.cpp:165] Memory required for data: 7528367520
I0117 19:40:27.788007 35429 layer_factory.hpp:77] Creating layer prob
I0117 19:40:27.788024 35429 net.cpp:100] Creating Layer prob
I0117 19:40:27.788038 35429 net.cpp:434] prob <- fc8_my-fc8_0_split_0
I0117 19:40:27.788053 35429 net.cpp:408] prob -> prob
I0117 19:40:27.788432 35429 net.cpp:150] Setting up prob
I0117 19:40:27.788460 35429 net.cpp:157] Top shape: 40 2 (80)
I0117 19:40:27.788472 35429 net.cpp:165] Memory required for data: 7528367840
I0117 19:40:27.788494 35429 layer_factory.hpp:77] Creating layer accuracy
I0117 19:40:27.788512 35429 net.cpp:100] Creating Layer accuracy
I0117 19:40:27.788527 35429 net.cpp:434] accuracy <- prob
I0117 19:40:27.788540 35429 net.cpp:434] accuracy <- label_data_1_split_0
I0117 19:40:27.788555 35429 net.cpp:408] accuracy -> accuracy/top-1
I0117 19:40:27.788575 35429 net.cpp:150] Setting up accuracy
I0117 19:40:27.788592 35429 net.cpp:157] Top shape: (1)
I0117 19:40:27.788652 35429 net.cpp:165] Memory required for data: 7528367844
I0117 19:40:27.788666 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:27.788681 35429 net.cpp:100] Creating Layer loss
I0117 19:40:27.788694 35429 net.cpp:434] loss <- fc8_my-fc8_0_split_1
I0117 19:40:27.788709 35429 net.cpp:434] loss <- label_data_1_split_1
I0117 19:40:27.788723 35429 net.cpp:408] loss -> loss
I0117 19:40:27.788743 35429 layer_factory.hpp:77] Creating layer loss
I0117 19:40:27.789017 35429 net.cpp:150] Setting up loss
I0117 19:40:27.789042 35429 net.cpp:157] Top shape: (1)
I0117 19:40:27.789055 35429 net.cpp:160]     with loss weight 1
I0117 19:40:27.789075 35429 net.cpp:165] Memory required for data: 7528367848
I0117 19:40:27.789088 35429 net.cpp:226] loss needs backward computation.
I0117 19:40:27.789099 35429 net.cpp:228] accuracy does not need backward computation.
I0117 19:40:27.789111 35429 net.cpp:228] prob does not need backward computation.
I0117 19:40:27.789124 35429 net.cpp:226] fc8_my-fc8_0_split needs backward computation.
I0117 19:40:27.789136 35429 net.cpp:226] my-fc8 needs backward computation.
I0117 19:40:27.789147 35429 net.cpp:226] relu7 needs backward computation.
I0117 19:40:27.789158 35429 net.cpp:226] fc7 needs backward computation.
I0117 19:40:27.789170 35429 net.cpp:226] relu6 needs backward computation.
I0117 19:40:27.789180 35429 net.cpp:226] fc6 needs backward computation.
I0117 19:40:27.789191 35429 net.cpp:226] pool5 needs backward computation.
I0117 19:40:27.789202 35429 net.cpp:226] relu5a needs backward computation.
I0117 19:40:27.789213 35429 net.cpp:226] conv5a needs backward computation.
I0117 19:40:27.789224 35429 net.cpp:226] pool4 needs backward computation.
I0117 19:40:27.789237 35429 net.cpp:226] relu4a needs backward computation.
I0117 19:40:27.789247 35429 net.cpp:226] conv4a needs backward computation.
I0117 19:40:27.789258 35429 net.cpp:226] pool3 needs backward computation.
I0117 19:40:27.789270 35429 net.cpp:226] relu3a needs backward computation.
I0117 19:40:27.789281 35429 net.cpp:226] conv3a needs backward computation.
I0117 19:40:27.789294 35429 net.cpp:226] pool2 needs backward computation.
I0117 19:40:27.789305 35429 net.cpp:226] relu2a needs backward computation.
I0117 19:40:27.789317 35429 net.cpp:226] conv2a needs backward computation.
I0117 19:40:27.789330 35429 net.cpp:226] pool1 needs backward computation.
I0117 19:40:27.789340 35429 net.cpp:226] relu1a needs backward computation.
I0117 19:40:27.789352 35429 net.cpp:226] conv1a needs backward computation.
I0117 19:40:27.789364 35429 net.cpp:228] label_data_1_split does not need backward computation.
I0117 19:40:27.789376 35429 net.cpp:228] data does not need backward computation.
I0117 19:40:27.789388 35429 net.cpp:270] This network produces output accuracy/top-1
I0117 19:40:27.789399 35429 net.cpp:270] This network produces output loss
I0117 19:40:27.789425 35429 net.cpp:283] Network initialization done.
I0117 19:40:27.789575 35429 solver.cpp:60] Solver scaffolding done.
I0117 19:40:27.790215 35429 caffe.cpp:251] Starting Optimization
I0117 19:40:27.790241 35429 solver.cpp:279] Solving c3d_arrow
I0117 19:40:27.790252 35429 solver.cpp:280] Learning Rate Policy: step
I0117 19:40:27.791743 35429 solver.cpp:337] Iteration 0, Testing net (#0)
I0117 19:40:27.802455 35429 blocking_queue.cpp:50] Data layer prefetch queue empty
I0117 20:15:08.997938 35429 solver.cpp:404]     Test net output #0: accuracy/top-1 = 0.498387
I0117 20:15:08.999783 35429 solver.cpp:404]     Test net output #1: loss = 0.706326 (* 1 = 0.706326 loss)
I0117 20:15:08.999806 35429 solver.cpp:337] Iteration 0, Testing net (#1)
I0117 20:41:23.849071 35429 solver.cpp:404]     Test net output #0: accuracy/top-1 = 0.5
I0117 20:41:23.850766 35429 solver.cpp:404]     Test net output #1: loss = 0.705795 (* 1 = 0.705795 loss)
F0117 20:41:23.853289 35429 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
    @     0x2aaaac545c0d  google::LogMessage::Fail()
    @     0x2aaaac547a7f  google::LogMessage::SendToLog()
    @     0x2aaaac5457a3  google::LogMessage::Flush()
    @     0x2aaaac54839e  google::LogMessageFatal::~LogMessageFatal()
    @     0x2aaaab416091  caffe::SyncedMemory::to_gpu()
    @     0x2aaaab415429  caffe::SyncedMemory::mutable_gpu_data()
    @     0x2aaaab2866c2  caffe::Blob<>::mutable_gpu_data()
    @     0x2aaaab461ce7  caffe::CudnnNdConvolutionLayer<>::Forward_gpu()
    @     0x2aaaab3de008  caffe::Net<>::ForwardFromTo()
    @     0x2aaaab3de387  caffe::Net<>::Forward()
    @     0x2aaaab3fd5ef  caffe::Solver<>::Step()
    @     0x2aaaab3fdea9  caffe::Solver<>::Solve()
    @           0x40ba4b  train()
    @           0x4089ac  main
    @     0x2aaab8c01b15  __libc_start_main
    @           0x40936d  (unknown)
